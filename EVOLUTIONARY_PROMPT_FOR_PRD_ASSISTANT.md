# Rigorous Evolutionary Prompt Optimization for product-requirements-assistant

**Execute this prompt in the product-requirements-assistant workspace to achieve +12% quality improvements through systematic evolutionary optimization.**

---

## ðŸŽ¯ **EXECUTION COMMAND**

```
I'm ready to execute rigorous evolutionary prompt optimization for product-requirements-assistant. I will establish a baseline with 8 diverse PRD test cases, then execute 20 rounds of scored mutations with keep/discard logic, followed by 40-round extended optimization to determine optimal iteration count. This will answer definitively whether "more rounds = better results." Beginning with baseline establishment.
```

---

## ðŸ”¬ **CRITICAL METHODOLOGY - READ FIRST**

### Reference Documents (GitHub URLs):
- **Complete Instructions**: https://github.com/bordenet/one-pager/blob/main/AI_AGENT_GENERALIZED_PROMPT_TUNING_INSTRUCTIONS.md
- **Technical Design**: https://github.com/bordenet/one-pager/blob/main/GENERALIZED_PROMPT_TUNING_DESIGN.md
- **Business Requirements**: https://github.com/bordenet/one-pager/blob/main/GENERALIZED_PROMPT_TUNING_PRD.md

### Key "Ah-Ha!" Moments You MUST Apply:

1. **Adversarial Tension**: Phase 2 (Gemini) must generate DELIBERATELY DIFFERENT approach from Phase 1 (Claude), not just "review and improve"
2. **Evolutionary Logic**: Each prompt change is a mutation. If new_score > previous_score: KEEP. If not: DISCARD. No exceptions.
3. **Multi-Round Evolution**: 20-40 small mutations with objective scoring beats single large changes
4. **Rigorous Scoring**: Every output scored with specific evidence. No subjective judgment allowed.

---

## ðŸ“‹ **EXECUTION PHASES**

### Phase A: Rigorous Baseline (Required)
1. **Generate 8 Diverse PRD Test Cases**:
   - B2B SaaS feature, Mobile app redesign, API platform, Internal tool
   - Vary complexity: Simple feature â†’ Complex system â†’ Integration â†’ Migration
   - Include realistic business context, stakeholders, quantifiable goals
   - Cover different industries, audiences, constraints

2. **Execute Current Prompts**:
   - Run all 8 test cases through 3-phase workflow
   - YOU act as both Claude (Phase 1, 3) and Gemini (Phase 2)
   - Follow current prompts exactly - no improvements yet
   - Capture all outputs

3. **Score Using PRD Rubric**:
   - **Comprehensiveness** (1-5): Covers all necessary PRD aspects?
   - **Clarity** (1-5): Requirements unambiguous and specific?
   - **Structure** (1-5): Proper section numbering (## 1. Executive Summary, ### 1.1)?
   - **Consistency** (1-5): Aligned across all three phases?
   - **Engineering-Ready** (1-5): Focuses on "why" and "what", avoids "how"?
   - **No Metadata Table** (Pass/Fail): Follows user requirement?
   - **Section Numbering** (Pass/Fail): Uses numbered sections?

4. **Document Baseline**: Calculate average score, identify common weaknesses

### Phase B: 20-Round Evolution (Required)
**For Each Round (1-20)**:
1. **Identify Target**: Lowest-scoring criterion or most common issue
2. **Design Mutation**: ONE specific, testable change to prompts
3. **Apply & Test**: Modify prompts, re-run ALL 8 test cases
4. **Score & Decide**: Calculate new average. If improved: KEEP. If not: DISCARD.
5. **Document**: Record mutation, scores, decision, rationale

**Example Mutations**:
- Add explicit word count limits for conciseness
- Require specific business metrics for comprehensiveness
- Strengthen section numbering requirements for structure
- Enhance Phase 2 adversarial instructions for consistency

### Phase C: 40-Round Extended (Required)
- **Continue Evolution**: Rounds 21-40 with advanced mutations
- **Track Diminishing Returns**: When do improvements plateau?
- **Advanced Strategies**: Combination improvements, cross-phase optimizations

### Phase D: Comparative Analysis (Required)
- **Compare Results**: 20-round vs 40-round final scores
- **Efficiency Analysis**: Improvement per round, optimal stopping point
- **Answer Key Question**: Is more always better?

---

## ðŸŽ¯ **SUCCESS CRITERIA**

### Quantitative Requirements:
- [ ] â‰¥12% improvement over baseline (proven benchmark)
- [ ] All 8 test cases show improvement or maintain quality
- [ ] No regressions >0.5 points on any test case
- [ ] Complete mutation log with all decisions documented

### Qualitative Requirements:
- [ ] Definitive answer on 20-round vs 40-round effectiveness
- [ ] Identification of most effective mutation types
- [ ] Clear diminishing returns analysis
- [ ] Production-ready optimized prompts

### Documentation Requirements:
- [ ] Baseline report with 8 test cases and scores
- [ ] Round-by-round mutation log (all 40 rounds)
- [ ] Comparative analysis: 20 vs 40 rounds
- [ ] Final optimized prompt files ready for deployment

---

## ðŸ”¬ **CRITICAL EXECUTION NOTES**

### Objectivity Requirements:
- **Score with Evidence**: Every score must cite specific examples from output
- **No Subjective Bias**: Keep/discard based solely on numerical scores
- **Consistent Standards**: Apply same rubric to all test cases, all rounds

### Adversarial Understanding:
- **Phase 2 is NOT Review**: Gemini must offer genuinely different approach
- **Create Tension**: Value comes from different perspectives, not agreement
- **Maintain Constructive**: Different but still helpful and professional

### Mutation Discipline:
- **One Change Per Round**: Never apply multiple mutations simultaneously
- **Specific and Reversible**: Each mutation must be clearly defined
- **Test Everything**: Re-run ALL test cases after each mutation

---

## ðŸ“Š **EXPECTED DELIVERABLES**

1. **Baseline Analysis**: 8 test cases, current performance, weakness patterns
2. **20-Round Results**: Mutation log, final score, improvement trajectory
3. **40-Round Results**: Extended optimization, diminishing returns analysis
4. **Comparative Report**: Which approach is superior and why
5. **Optimized Prompts**: Best-performing versions ready for production
6. **Methodology Insights**: Transferable lessons for other Genesis projects

---

**This evolutionary methodology transforms prompt optimization from subjective art into objective science, delivering consistent +12% improvements through rigorous iteration and scoring.**

**Begin execution now with the command above. Document every step, score every output, justify every decision.**
